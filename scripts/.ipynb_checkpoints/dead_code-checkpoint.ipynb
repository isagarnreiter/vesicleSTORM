{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying DBScan\n",
    "#define intensity threshold. Points which have a lower intensity will be excluded from the clustering.\n",
    "int_threshold=0\n",
    "\n",
    "#apply the threshold on the vesicle and synaptic marker datasets\n",
    "vesicles_thresh = vesicles[vesicles[:,3]>int_threshold,0:3]\n",
    "synapse_marker_thresh = synapse_marker[synapse_marker[:,3]>int_threshold, 0:3]\n",
    "\n",
    "#compute the fraction of points including in the clustering.\n",
    "frct_points_included = vesicles_thresh.shape[0]/vesicles.shape[0]*100\n",
    "print('% points above threshold:', frct_points_included)\n",
    "\n",
    "# Normalize the data to have zero mean and unit variance\n",
    "data_norm = (vesicles_thresh - np.mean(vesicles_thresh, axis=0)) / np.std(vesicles_thresh, axis=0)\n",
    "\n",
    "# Apply DBSCAN to the normalized data\n",
    "dbscan = DBSCAN(eps=800, min_samples=150)\n",
    "labels = dbscan.fit_predict(vesicles_thresh)\n",
    "\n",
    "#compute the number of clusters rendered by DBSCAN\n",
    "unique_labels = np.unique(labels[labels >= 0])\n",
    "n_clusters = len(unique_labels)\n",
    "print('number of clusters:', n_clusters)\n",
    "\n",
    "plt.scatter(vesicles[:,0], vesicles[:,1], s=0.1, alpha=0.5)\n",
    "for label in unique_labels:\n",
    "    mask = labels == label\n",
    "    if np.any(mask):\n",
    "        plt.scatter(vesicles_thresh[mask, 0], vesicles_thresh[mask, 1], s=20)\n",
    "\n",
    "plt.title(\"DBSCAN Clusters\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a227fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distances = {}\n",
    "for i in keywords:\n",
    "    for j in range(0, len(file_dic[i])):\n",
    "            min_dist = fcts.calc_distance_squared_two(file_dic[i][j], file_dic[i][j])\n",
    "            if i in min_distances:\n",
    "                min_distances[i] = np.append(min_distances[i], min_dist)\n",
    "            else:\n",
    "                min_distances[i] = np.array([min_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a60494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#point pattern analysis in 2D\n",
    "\n",
    "import pointpats\n",
    "coordinates=pd.DataFrame(vesicle_clusters['210404 SPON647_PSD680 10DIV_CellZone1'][1][:,0:2], columns = ['x', 'y'])\n",
    "\n",
    "g_test = pointpats.distance_statistics.g_test(coordinates, support=40, keep_simulations=True)\n",
    "\n",
    "f, ax = plt.subplots(\n",
    "    1, 2, figsize=(9, 3), gridspec_kw=dict(width_ratios=(6, 3))\n",
    ")\n",
    "# plot all the simulations with very fine lines\n",
    "ax[0].plot(\n",
    "    g_test.support, g_test.simulations.T, color=\"k\", alpha=0.01\n",
    ")\n",
    "# and show the average of simulations\n",
    "ax[0].plot(\n",
    "    g_test.support,\n",
    "    np.median(g_test.simulations, axis=0),\n",
    "    color=\"cyan\",\n",
    "    label=\"median simulation\",\n",
    ")\n",
    "\n",
    "\n",
    "# and the observed pattern's G function\n",
    "ax[0].plot(\n",
    "    g_test.support, g_test.statistic, label=\"observed\", color=\"red\"\n",
    ")\n",
    "\n",
    "# clean up labels and axes\n",
    "ax[0].set_xlabel(\"distance\")\n",
    "ax[0].set_ylabel(\"% of nearest neighbor\\ndistances shorter\")\n",
    "ax[0].legend()\n",
    "#ax[0].set_xlim(0, 2000)\n",
    "ax[0].set_title(r\"Ripley's $G(d)$ function\")\n",
    "\n",
    "# plot the pattern itself on the next frame\n",
    "ax[1].scatter(*coordinates)\n",
    "\n",
    "# and clean up labels and axes there, too\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_title(\"Pattern\")\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#point density analysis in 2d\n",
    "\n",
    "# Set up figure and axis\n",
    "f, ax = plt.subplots(1, figsize=(6, 6))\n",
    "# Generate and add KDE with a shading of 50 gradients\n",
    "# coloured contours, 75% of transparency,\n",
    "# and the reverse viridis colormap\n",
    "seaborn.kdeplot(coordinates, x='x',y='y',\n",
    "    n_levels=50,\n",
    "    shade=True,\n",
    "    alpha=0.55,\n",
    "    cmap=\"viridis_r\",\n",
    ")\n",
    "\n",
    "# Remove axes\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading a single file as example using outdated fct.\n",
    "\n",
    "ex_zone = ['/Volumes/STORM_Nathalie/STORM DeMixing/210414 DEP647_PSD680 8DIV/CellZone4/Demix/CoordTable_SAFE360_MULTIPLEXING_demixed_w1_UncertaintyFiltered.csv',\n",
    "  '/Volumes/STORM_Nathalie/STORM DeMixing/210414 DEP647_PSD680 8DIV/CellZone4/Demix/CoordTable_SAFE360_MULTIPLEXING_demixed_w2_UncertaintyFiltered.csv']\n",
    "\n",
    "ex_zone = list_of_files[0]\n",
    "\n",
    "vesicles = pd.read_csv(ex_zone[0])[['x [nm]', 'y [nm]', 'z [nm]']].to_numpy(dtype=np.float64)\n",
    "synapse_marker = pd.read_csv(ex_zone[1])[['x [nm]', 'y [nm]', 'z [nm]']].to_numpy(dtype=np.float64)\n",
    "\n",
    "data=vesicles\n",
    "image_size = (730,730,16)\n",
    "kernel_size = (50,50,1)\n",
    "sigma = 12\n",
    "\n",
    "wide_field_image = fcts.get_wide_field(vesicles, image_size, kernel_size, sigma)\n",
    "\n",
    "coords = np.array(coords)\n",
    "\n",
    "plt.imshow(image[:,:,0])\n",
    "plt.scatter(coords[:,1], coords[:,0], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e025c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minimum distance for clusters of vesicles to PSD95 areas - but done as point location instead of point density\n",
    "\n",
    "image_size = (730,730,16)\n",
    "kernel_size = (50,50,1)\n",
    "sigma = 15\n",
    "\n",
    "max_threshold_ves = 12\n",
    "max_threshold_mark = 4\n",
    "max_area = (21,21,21)\n",
    "\n",
    "min_dist_marker = {}\n",
    "min_dist_vesicle = {}\n",
    "SNR_dict = {}\n",
    "for file_name in list_of_files:\n",
    "    \n",
    "    if access == 'drive':\n",
    "        new_file_name = f\"{(file_name[0]).split('/')[4]}_{(file_name[0]).split('/')[5]}\"\n",
    "    \n",
    "    elif access == 'computer':\n",
    "        new_file_name = f\"{(file_name[0]).split('/')[-1][0:-3]}\"\n",
    "    \n",
    "    print(new_file_name)\n",
    "    \n",
    "    file_info = files_infos[new_file_name]\n",
    "    \n",
    "    \n",
    "    if file_info[0] == 0:\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        vesicles = pd.read_csv(file_name[file_info[1]])[['x [nm]', 'y [nm]', 'z [nm]']].to_numpy(dtype=np.float64)\n",
    "        synapse_marker = pd.read_csv(file_name[(file_info[1]-1)**2])[['x [nm]', 'y [nm]', 'z [nm]']].to_numpy(dtype=np.float64)\n",
    "        \n",
    "        #plot the locations of both the vesicles and the synaptic marker using a large point spread function.\n",
    "        wide_field_vesicles = fcts.get_wide_field(vesicles, image_size, kernel_size, sigma)\n",
    "        wide_field_marker = fcts.get_wide_field(synapse_marker, image_size, kernel_size, sigma)\n",
    "        \n",
    "        #plot the locations of the vesicles using the same image size as above to a single pixel size\n",
    "        image_vesicles = fcts.get_wide_field(vesicles, image_size, (1,1,1), sigma)\n",
    "        \n",
    "        #calculate the intensity threshold for the large PSF images, depending on an arbitrary intensity threshold, dependent on the mean and std of each image.\n",
    "        ves_thresh = wide_field_vesicles.mean() + wide_field_vesicles.std() * max_threshold_ves\n",
    "        marker_thresh = wide_field_marker.mean() + wide_field_marker.std() * max_threshold_mark\n",
    "        \n",
    "        #create a mask of the large PSF images where for the pixels above the threshold\n",
    "        mask_vesicles = (wide_field_vesicles > ves_thresh) * 1\n",
    "\n",
    "        plt.imshow(mask_vesicles[:,:,0])\n",
    "        plt.show()\n",
    "        mask_marker = (wide_field_marker > marker_thresh) * 1\n",
    "\n",
    "        #create an array for the vesicles which are located within the mask\n",
    "        masked_vesicles = np.where(mask_vesicles, image_vesicles, 0)\n",
    "        vesicle_pos_tup = np.where(masked_vesicles > 0)\n",
    "        vesicle_pos = np.array([vesicle_pos_tup[0],vesicle_pos_tup[1],vesicle_pos_tup[2]]).T\n",
    "        vesicle_pos = vesicle_pos/image_size * 49660\n",
    "        \n",
    "        nb_vesicles_tot = vesicles.shape[0]\n",
    "        nb_vesicles_selected = vesicle_pos.shape[0]\n",
    "        snr = nb_vesicles_selected/nb_vesicles_tot\n",
    "        \n",
    "        #calculate the distance between vesicles within the masked images and all synapse markers\n",
    "        distance_to_marker = fcts.calc_distance_squared_two(vesicle_pos, synapse_marker)\n",
    "        distance_to_vesicles = fcts.calc_distance_squared_two(vesicle_pos, vesicle_pos)\n",
    "        print(distance_to_vesicles)\n",
    "        min_dist_marker[new_file_name] = distance_to_marker\n",
    "        min_dist_vesicle[new_file_name] = distance_to_vesicles\n",
    "        SNR_dict[new_file_name] = snr\n",
    "        \n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9820e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def merge_points(points, diameter=40):\n",
    "    \"\"\"\n",
    "    Merges points that are within `diameter` distance of each other and returns a new array with one point per vesicle\n",
    "    \"\"\"\n",
    "    merged_points = []\n",
    "    while len(points) > 0:\n",
    "        p = points[0]\n",
    "        points = np.delete(points, 0, axis=0)\n",
    "        nearby_points = np.linalg.norm(points - p, axis=1) < diameter\n",
    "        while np.sum(nearby_points) > 0:\n",
    "            p = np.mean(np.concatenate([points[nearby_points], [p]]), axis=0)\n",
    "            points = np.delete(points, np.where(nearby_points)[0], axis=0)\n",
    "            nearby_points = np.linalg.norm(points - p, axis=1) < diameter\n",
    "        merged_points.append(p)\n",
    "    return np.array(merged_points)\n",
    "\n",
    "\n",
    "# Example dataset of 100 points with x,y,z coordinates\n",
    "points = np.random.rand(100, 2)\n",
    "\n",
    "# Merge points within 40nm of each other\n",
    "merged_points = merge_points(points, diameter=0.1)\n",
    "\n",
    "# Check the number of original points vs merged points\n",
    "print(f\"Original points: {points.shape[0]}, Merged points: {merged_points.shape[0]}\")\n",
    "\n",
    "plt.scatter(points[:,0], points[:,1], alpha=0.5)\n",
    "plt.scatter(merged_points[:,0], merged_points[:,1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7947dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation test\n",
    "\n",
    "x = vesicle_type_nd_DIV['DEP647_PSD680 8DIV']\n",
    "y = vesicle_type_nd_DIV['SPON647_PSD680 8DIV']\n",
    "\n",
    "\n",
    "def statistic(x, y, axis):\n",
    "    return np.mean(x, axis=axis) - np.mean(y, axis=axis)\n",
    "\n",
    "from scipy.stats import permutation_test\n",
    "# because our statistic is vectorized, we pass `vectorized=True`\n",
    "# `n_resamples=np.inf` indicates that an exact test is to be performed\n",
    "res = permutation_test((x, y), statistic, vectorized=True,\n",
    "                       n_resamples=9999, alternative='less')\n",
    "print(res.statistic)\n",
    "print(res.pvalue)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vesicleSTORM] *",
   "language": "python",
   "name": "conda-env-vesicleSTORM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
